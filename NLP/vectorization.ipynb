{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "\n",
    "plt.style.use(\"default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization\n",
    "\n",
    "Process of encoding texts as integers as to create feature vectors\n",
    "\n",
    "**Feature Vector:** vector of numerical features that represent an object\n",
    "\n",
    "**Types of Vectorization:**\n",
    "- Count Vectorization/unigram\n",
    "- N-Grams\n",
    "- TF-IDF\n",
    "\n",
    "### Count Vectorization/UniGram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### to give unique integer value to the different words, we need to fit the texts with the `CountVectorizer`. Then it'll assign the unique values\n",
    "\n",
    "**fitting** also means I'm training with some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.feature_extraction.text.CountVectorizer"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [\"Whoever is happy will make others happy too.\",\n",
    "          \"Stay healthy, stay happy\"]\n",
    "\n",
    "X = cv.fit(corpus)\n",
    "type(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### to see the identified different words that the `CountVectorizer` found in the fitting process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['happy', 'healthy', 'is', 'make', 'others', 'stay', 'too', 'whoever', 'will']\n"
     ]
    }
   ],
   "source": [
    "print(X.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### to see the unique number generated for unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'whoever': 7, 'is': 2, 'happy': 0, 'will': 8, 'make': 3, 'others': 4, 'too': 6, 'stay': 5, 'healthy': 1}\n"
     ]
    }
   ],
   "source": [
    "print(X.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### if you're confused from where I got the above two attributes of X: `X.vocabulary_` and `X.get_feature_names()`, there is a function `dir()` to see what functions and attributes are defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_char_ngrams',\n",
       " '_char_wb_ngrams',\n",
       " '_check_n_features',\n",
       " '_check_stop_words_consistency',\n",
       " '_check_vocabulary',\n",
       " '_count_vocab',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_limit_features',\n",
       " '_more_tags',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_sort_features',\n",
       " '_stop_words_id',\n",
       " '_validate_data',\n",
       " '_validate_params',\n",
       " '_validate_vocabulary',\n",
       " '_warn_for_unused_params',\n",
       " '_white_spaces',\n",
       " '_word_ngrams',\n",
       " 'analyzer',\n",
       " 'binary',\n",
       " 'build_analyzer',\n",
       " 'build_preprocessor',\n",
       " 'build_tokenizer',\n",
       " 'decode',\n",
       " 'decode_error',\n",
       " 'dtype',\n",
       " 'encoding',\n",
       " 'fit',\n",
       " 'fit_transform',\n",
       " 'fixed_vocabulary_',\n",
       " 'get_feature_names',\n",
       " 'get_params',\n",
       " 'get_stop_words',\n",
       " 'input',\n",
       " 'inverse_transform',\n",
       " 'lowercase',\n",
       " 'max_df',\n",
       " 'max_features',\n",
       " 'min_df',\n",
       " 'ngram_range',\n",
       " 'preprocessor',\n",
       " 'set_params',\n",
       " 'stop_words',\n",
       " 'stop_words_',\n",
       " 'strip_accents',\n",
       " 'token_pattern',\n",
       " 'tokenizer',\n",
       " 'transform',\n",
       " 'vocabulary',\n",
       " 'vocabulary_']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now transform our data based on training data\n",
    "\n",
    "**Note:** We should not transform the train data, we should transform on test/new data. But for simplicity, let's try on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(sklearn.feature_extraction.text.CountVectorizer, scipy.sparse.csr.csr_matrix)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transformed = cv.transform(corpus)\n",
    "type(X), type(X_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As X_transformed is matrix, let's check its shape\n",
    "X_transformed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`shape = (2, 9)` ðŸ‘‰ `R=2` and `C=9`, We had 2 text data in the corpus list and we got 9 unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t2\n",
      "  (0, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 8)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 5)\t2\n"
     ]
    }
   ],
   "source": [
    "print(X_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### let's convert the transformed X into array to visualize it better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 1, 1, 1, 0, 1, 1, 1],\n",
       "       [1, 1, 0, 0, 0, 2, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_array = X_transformed.toarray()\n",
    "X_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['happy', 'healthy', 'is', 'make', 'others', 'stay', 'too', 'whoever', 'will']\n"
     ]
    }
   ],
   "source": [
    "print(X.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**obseravtion:** It's difficult to understand the above array. let's convert it to `pandas` daraframe to visualize clearly.\n",
    "\n",
    "- We need to add the data and also to add column values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>happy</th>\n",
       "      <th>healthy</th>\n",
       "      <th>is</th>\n",
       "      <th>make</th>\n",
       "      <th>others</th>\n",
       "      <th>stay</th>\n",
       "      <th>too</th>\n",
       "      <th>whoever</th>\n",
       "      <th>will</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   happy  healthy  is  make  others  stay  too  whoever  will\n",
       "0      2        0   1     1       1     0    1        1     1\n",
       "1      1        1   0     0       0     2    0        0     0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=X_array, columns=X.get_feature_names())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Whoever is happy will make others happy too.', 'Stay healthy, stay happy']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**observation:** from tha above dataframe, we see that it shows the frequency of each words in the corresponsing sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try to transform on new text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>happy</th>\n",
       "      <th>healthy</th>\n",
       "      <th>is</th>\n",
       "      <th>make</th>\n",
       "      <th>others</th>\n",
       "      <th>stay</th>\n",
       "      <th>too</th>\n",
       "      <th>whoever</th>\n",
       "      <th>will</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   happy  healthy  is  make  others  stay  too  whoever  will\n",
       "0      0        1   0     0       0     0    0        0     0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [\"early to bed, early to rise, makes a man healthy, wealthy and wise\"]\n",
    "\n",
    "test_transformed = cv.transform(test)\n",
    "pd.DataFrame(data=test_transformed.toarray(), columns=X.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**observation:** the unknown words w.r.t the fitted words are eliminated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Grams vectorization\n",
    "\n",
    "- bigram\n",
    "- trigram\n",
    "- 4-gram\n",
    "\n",
    "in `countvectorization`, we lose information about the neighbouring words.\n",
    "\n",
    "Example word: \"I am studying NLP\"\n",
    "\n",
    "- bigram - \"I am\", \"am studying\", \"studying NLP\"\n",
    "- trigram - \"I am studying\", \"am studying NLP\"\n",
    "- 4-gram - \"I am studying NLP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(ngram_range=(2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We previously initialized\n",
    "\n",
    "```py\n",
    "cv = CountVectorizer()\n",
    "```\n",
    "\n",
    "we didn't define `ngram_range` hyper-parameter previously when we worked with `CountVectorize/UniGram` technique because by default its set to `ngram_range=(1, 1)`\n",
    "\n",
    "```py\n",
    "cv = CountVectorizer(ngram_range=(2, 3))\n",
    "```\n",
    "\n",
    "means, we're doing `bigram` and `trigram`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>happy too</th>\n",
       "      <th>happy will</th>\n",
       "      <th>happy will make</th>\n",
       "      <th>healthy stay</th>\n",
       "      <th>healthy stay happy</th>\n",
       "      <th>is happy</th>\n",
       "      <th>is happy will</th>\n",
       "      <th>make others</th>\n",
       "      <th>make others happy</th>\n",
       "      <th>others happy</th>\n",
       "      <th>others happy too</th>\n",
       "      <th>stay happy</th>\n",
       "      <th>stay healthy</th>\n",
       "      <th>stay healthy stay</th>\n",
       "      <th>whoever is</th>\n",
       "      <th>whoever is happy</th>\n",
       "      <th>will make</th>\n",
       "      <th>will make others</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   happy too  happy will  happy will make  healthy stay  healthy stay happy  \\\n",
       "0          1           1                1             0                   0   \n",
       "1          0           0                0             1                   1   \n",
       "\n",
       "   is happy  is happy will  make others  make others happy  others happy  \\\n",
       "0         1              1            1                  1             1   \n",
       "1         0              0            0                  0             0   \n",
       "\n",
       "   others happy too  stay happy  stay healthy  stay healthy stay  whoever is  \\\n",
       "0                 1           0             0                  0           1   \n",
       "1                 0           1             1                  1           0   \n",
       "\n",
       "   whoever is happy  will make  will make others  \n",
       "0                 1          1                 1  \n",
       "1                 0          0                 0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [\"Whoever is happy will make others happy too.\",\n",
    "          \"Stay healthy, stay happy\"]\n",
    "\n",
    "# fit and transform in a single command\n",
    "X = cv.fit_transform(corpus)\n",
    "\n",
    "# convert into dataframe\n",
    "pd.DataFrame(X.toarray(), columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `TF-IDF (Term Frequency-Inverse Document Frequency)` vectorizer\n",
    "\n",
    "$TF = \\frac{numberOfTimesOccuredInTheSentence}{totalWordInTheSentence}$\n",
    "\n",
    "$IDF = log(\\frac{numberOfSentences}{totalOccurenceOfTheWordInTheWholeDataset})$\n",
    "\n",
    "So, ```TF-IDF = TF * IDF```\n",
    "\n",
    "Suppose we have 200 sentences, the first sentence is: _`NLP is an exciting field`_. If we consider the `exciting` word, and suppose it occurs 4 times in the whole dataset.\n",
    "\n",
    "$tf = \\frac{1}{5} = 0.20$\n",
    "\n",
    "$idf = log(\\frac{200}{4}) = 1.7$\n",
    "\n",
    "so, `tf-idf` value of _exciting_ word = 0.25 * 1.7 = 0.34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sky blue', 'sky blue']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [\"The sky is blue\", \"The sky is not blue\"]\n",
    "\n",
    "def clean_text(txt):\n",
    "    txt_no_punc = \"\".join([c for c in txt if c not in string.punctuation])\n",
    "    tokens = word_tokenize(txt_no_punc.lower())\n",
    "    txt_stem = \" \".join([ps.stem(word) for word in tokens if word not in stopwords.words(\"english\")])\n",
    "    return txt_stem\n",
    "\n",
    "corpus_no_sw = list(map(lambda val: clean_text(val), corpus))\n",
    "    \n",
    "corpus_no_sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blue</th>\n",
       "      <th>sky</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       blue       sky\n",
       "0  0.707107  0.707107\n",
       "1  0.707107  0.707107"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tfidf.fit_transform(corpus_no_sw)\n",
    "\n",
    "pd.DataFrame(X.toarray(), columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.075"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "0.25*0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.5)*np.log10(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
